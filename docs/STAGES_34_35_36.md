# Manifold Stages 34-36: Baseline Geometry

Three new Manifold stages that compute per-cycle health scoring against a healthy
reference baseline. These are the core innovation for RUL prediction — rt_centroid_dist
from stage 35 is the #2 most important ML feature.

## Stage 34: Fleet Baseline

**File:** `manifold/engines/entry_points/stage_34_cohort_baseline.py`

SVD on early-life observations to establish a healthy reference.

### Two Modes

| Mode | Description | Output Rows | When to Use |
|------|-------------|-------------|-------------|
| `fleet` (default) | Pool ALL cohorts' first 20% into ONE baseline | 1 | Single-regime (FD001, FD003) |
| `per_cohort` | Individual baseline per cohort | N cohorts | Multi-regime or genuinely different cohorts |

### Fleet Mode Algorithm

```
1. For each cohort, pivot observations to wide format (I × signals)
2. Take first 20% of cycles (baseline_fraction)
3. Pool all cohorts' early-life: X_pool = [X_early_1; X_early_2; ... X_early_N]
4. Compute centroid = mean(X_pool)
5. Compute std = std(X_pool)
6. Normalize: X_norm = (X_pool - centroid) / std
7. SVD: X_norm = U S V^T
8. Store: centroid, std, eigenvalues, principal directions (top 5)
```

### Output Schema: `cohort_baseline.parquet`

| Column | Type | Description |
|--------|------|-------------|
| cohort | str | 'fleet' or engine name |
| n_baseline_cycles | i64 | Pooled cycle count (4,086 for FD001 fleet) |
| n_total_cycles | i64 | Total cycles in pool |
| n_signals | i64 | Number of sensors (24 for FD001) |
| n_cohorts_pooled | i64 | Number of cohorts pooled (fleet mode only) |
| baseline_effective_dim | f64 | Dimensionality of healthy behavior |
| baseline_total_variance | f64 | Total energy in healthy state |
| baseline_eigenvalue_1-3 | f64 | Top 3 eigenvalues |
| baseline_explained_1-3 | f64 | Explained variance ratios |
| baseline_condition_number | f64 | Eigenvalue ratio (sensitivity) |
| centroid_json | str | Mean sensor vector (JSON array) |
| std_json | str | Per-sensor std (JSON array) |
| principal_directions_json | str | Top 5 eigenvectors (JSON nested array) |
| signal_ids_json | str | Signal column names (JSON array) |

### FD001 Fleet Baseline Stats
- Pooled cycles: 4,086 (100 engines × ~41 cycles each)
- Effective dimension: 4.89
- Total variance: 17.00

### Critical Rule
**Fleet baseline MUST be computed from TRAINING data only.** Never include test data
in the baseline computation. Test engines are scored against the training fleet's
healthy reference.

---

## Stage 35: Observation Geometry

**File:** `manifold/engines/entry_points/stage_35_observation_geometry.py`

Per-cycle geometric scoring against the baseline from stage 34. This is a real-time
health indicator — computable from a single cycle's sensor readings.

### Algorithm

```
For each cycle I of each cohort:
    x = sensor_vector(I)                    # Raw sensor values at cycle I
    x_norm = (x - centroid) / std           # Normalize relative to fleet baseline
    centroid_distance = ||x_norm||           # Euclidean distance from healthy
    pc1_proj = x_norm · PC1                 # Projection onto primary variation axis
    pc2_proj = x_norm · PC2                 # Projection onto secondary axis
    mahalanobis = sqrt(Σ (proj_k² / λ_k))  # Eigenvalue-weighted distance
```

### Fleet vs Per-Cohort Mode

Stage 35 auto-detects:
- If baseline has `cohort='fleet'` → apply ONE baseline to ALL cohorts
- If baseline has per-cohort rows → match each cohort to its baseline

### Output Schema: `observation_geometry.parquet`

| Column | Type | Description |
|--------|------|-------------|
| cohort | str | Engine ID |
| I | i64 | Cycle number |
| centroid_distance | f64 | ||x_norm(I)|| — how far from healthy |
| centroid_distance_norm | f64 | centroid_distance / sqrt(n_signals) |
| pc1_projection | f64 | x_norm(I) · PC1 — primary degradation axis |
| pc2_projection | f64 | x_norm(I) · PC2 — lateral displacement |
| mahalanobis_approx | f64 | Eigenvalue-weighted distance |
| sensor_norm | f64 | ||x(I)|| — raw magnitude |

### FD001 Stats (fleet baseline)

| | Train | Test |
|---|---|---|
| Rows | 20,631 | 13,096 |
| Mean centroid_dist | 6.05 | 4.34 |
| Max centroid_dist | 35.01 | 17.49 |
| Mean mahalanobis | 3.63 | 2.38 |

Test mean is lower because test engines are cut before failure (less degraded on average).

### ML Impact

| Feature | LGB Importance | Rank |
|---------|---------------|------|
| rt_centroid_dist | 761 | **#2** |
| rt_centroid_dist_norm | 141 | #6 |
| rt_pc1_projection | — | low |
| rt_pc2_projection | — | low |
| mahalanobis_approx | — | low |

centroid_distance alone explains 70% of RUL variance in a linear model.

---

## Stage 36: Gaussian Similarity

**File:** `manifold/engines/entry_points/stage_36_gaussian_similarity.py`

Bhattacharyya distance between fitted Gaussians from stage 24 (gaussian_fingerprint).
Measures distributional similarity between signal pairs.

### Algorithm

For each pair of signals (a, b) within a cohort:
```
D_bhatt = (1/8)(μ_a - μ_b)² · 2/(σ_a² + σ_b²) + (1/2)ln((σ_a² + σ_b²) / (2·σ_a·σ_b))
```

### Output Schema: `gaussian_similarity.parquet`

| Column | Type | Description |
|--------|------|-------------|
| cohort | str | Engine ID |
| signal_a | str | First signal |
| signal_b | str | Second signal |
| n_features | i64 | Number of features compared |
| bhatt_mean | f64 | Mean Bhattacharyya distance |
| bhatt_max | f64 | Max distance (most different feature) |
| bhatt_min | f64 | Min distance (most similar feature) |

### ML Warning
Gaussian similarity features are **static per engine** and encode engine identity.
They cause catastrophic overfitting in cross-validated models. **Exclude gsim_* features
from ML models unless you have a way to normalize across engines.**

---

## Usage

### Compute Fleet Baseline + Score

```bash
# From manifold repo root

# 1. Fleet baseline from training fleet
./venv/bin/python -m engines.entry_points.stage_34_cohort_baseline \
    ~/data/FD001/train/observations.parquet \
    -o ~/data/FD001/fleet_baseline.parquet \
    --mode fleet

# 2. Score training data
./venv/bin/python -m engines.entry_points.stage_35_observation_geometry \
    ~/data/FD001/train/observations.parquet \
    --baseline ~/data/FD001/fleet_baseline.parquet \
    -o ~/data/FD001/train/output/observation_geometry.parquet

# 3. Score test data (against SAME fleet baseline)
./venv/bin/python -m engines.entry_points.stage_35_observation_geometry \
    ~/data/FD001/test/observations.parquet \
    --baseline ~/data/FD001/fleet_baseline.parquet \
    -o ~/data/FD001/test/output/observation_geometry.parquet
```

### Pipeline Integration

Stages 34-36 are registered in `run_pipeline.py` as CORE stages:
```python
CORE_STAGES = [
    ...
    'stage_34_cohort_baseline',       # SVD on early-life (healthy ref)
    'stage_35_observation_geometry',   # Per-cycle distance from baseline
    'stage_36_gaussian_similarity',    # Distributional distance
]
```

Dependencies:
```python
STAGE_DEPS = {
    'stage_34_cohort_baseline': ['observations.parquet'],
    'stage_35_observation_geometry': ['observations.parquet', 'cohort_baseline.parquet'],
    'stage_36_gaussian_similarity': ['gaussian_fingerprint.parquet'],
}
```
