"""
√òrthon Explorer
===============

A Streamlit app for exploring ORTHON four-layer analysis results.

Answers the fundamental questions:
    - WHAT is it? (Signal Typology)
    - HOW does it behave? (Behavioral Geometry)
    - WHEN/HOW does it change? (Dynamical Systems)
    - WHY does it change? (Causal Mechanics)

Features:
    - Load and explore parquet files from each layer
    - View LaTeX equations for mathematical foundations
    - Ask Claude to explain analysis in plain language

Usage:
    streamlit run orthon_explorer.py
"""

import streamlit as st
import polars as pl
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime

# Claude API (optional - graceful fallback if not installed)
try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False

# =============================================================================
# PAGE CONFIG
# =============================================================================

st.set_page_config(
    page_title="√òrthon Explorer",
    page_icon="‚óé",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =============================================================================
# CUSTOM CSS
# =============================================================================

st.markdown("""
<style>
    /* Main theme */
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A5F;
        margin-bottom: 0.5rem;
    }
    .tagline {
        font-size: 1.1rem;
        color: #666;
        font-style: italic;
        margin-bottom: 2rem;
    }

    /* Question cards */
    .question-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid;
    }
    .what-card { border-left-color: #4CAF50; }
    .how-card { border-left-color: #2196F3; }
    .when-card { border-left-color: #FF9800; }
    .why-card { border-left-color: #9C27B0; }

    .question-title {
        font-size: 1.3rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }

    /* Equation boxes */
    .equation-box {
        background: #fff;
        border: 1px solid #ddd;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        font-family: 'Computer Modern', serif;
    }

    /* Interpretation text */
    .interpretation {
        background: #f0f7ff;
        border-radius: 8px;
        padding: 1rem;
        margin-top: 1rem;
        line-height: 1.6;
    }

    /* Metric display */
    .metric-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
        gap: 1rem;
    }

    /* Footer */
    .footer {
        text-align: center;
        color: #888;
        margin-top: 3rem;
        padding-top: 1rem;
        border-top: 1px solid #eee;
    }
</style>
""", unsafe_allow_html=True)


# =============================================================================
# MATHEMATICAL EQUATIONS (LaTeX)
# =============================================================================

EQUATIONS = {
    "signal_typology": {
        "title": "Signal Typology ‚Äî WHAT is it?",
        "description": "Characterizes signals along six orthogonal behavioral axes.",
        "equations": {
            "Memory (Hurst Exponent)": r"H = \frac{\log(R/S)}{\log(n)} \quad \text{where } R/S = \frac{\max(Y_t) - \min(Y_t)}{\sigma}",
            "Periodicity (FFT)": r"\hat{f}(\omega) = \int_{-\infty}^{\infty} f(t) e^{-i\omega t} dt",
            "Volatility (GARCH)": r"\sigma_t^2 = \alpha_0 + \sum_{i=1}^{q} \alpha_i \epsilon_{t-i}^2 + \sum_{j=1}^{p} \beta_j \sigma_{t-j}^2",
            "Discontinuity (Heaviside)": r"H(t-t_0) = \begin{cases} 0 & t < t_0 \\ 1 & t \geq t_0 \end{cases}",
            "Impulsivity (Dirac)": r"\delta(t-t_0) = \lim_{\epsilon \to 0} \frac{1}{\epsilon} \Pi\left(\frac{t-t_0}{\epsilon}\right)",
            "Complexity (Entropy)": r"S = -\sum_{i} p_i \log(p_i)",
        },
    },
    "behavioral_geometry": {
        "title": "Behavioral Geometry ‚Äî HOW does it behave?",
        "description": "Analyzes pairwise relationships and network structure.",
        "equations": {
            "Gradient (Velocity)": r"\nabla E(t) = \frac{E(t+1) - E(t-1)}{2}",
            "Laplacian (Acceleration)": r"\nabla^2 E(t) = E(t+1) - 2E(t) + E(t-1)",
            "Divergence": r"\text{div}(E) = \sum_i \frac{\partial^2 E_i}{\partial t^2} \quad \begin{cases} >0 & \text{SOURCE} \\ <0 & \text{SINK} \end{cases}",
            "Field Potential": r"\phi = \int \|\nabla E\| \, dt = \sum_t |\nabla E(t)|",
            "Correlation": r"\rho_{xy} = \frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum(x_i - \bar{x})^2 \sum(y_i - \bar{y})^2}}",
            "Network Density": r"D = \frac{2|E|}{|V|(|V|-1)} \quad \text{where } |E| = \text{edges}, |V| = \text{nodes}",
        },
    },
    "dynamical_systems": {
        "title": "Dynamical Systems ‚Äî WHEN/HOW does it change?",
        "description": "Tracks regime evolution, stability, and trajectory.",
        "equations": {
            "Hamilton's Equations": r"\frac{dq}{dt} = \frac{\partial H}{\partial p}, \quad \frac{dp}{dt} = -\frac{\partial H}{\partial q}",
            "Lyapunov Exponent": r"\lambda = \lim_{t \to \infty} \frac{1}{t} \ln\left(\frac{|\delta x(t)|}{|\delta x(0)|}\right)",
            "Recurrence Rate": r"RR = \frac{1}{N^2} \sum_{i,j} R_{i,j} \quad \text{where } R_{i,j} = \Theta(\varepsilon - \|X_i - X_j\|)",
            "Determinism": r"DET = \frac{\sum_{l=l_{min}}^{N} l \cdot P(l)}{\sum_{i,j} R_{i,j}}",
            "Stability Index": r"\sigma = 1 - \frac{|\Delta \rho|}{\max(|\Delta \rho|)}",
            "Trajectory Curvature": r"\kappa = \frac{|x'y'' - y'x''|}{(x'^2 + y'^2)^{3/2}}",
        },
    },
    "causal_mechanics": {
        "title": "Causal Mechanics ‚Äî WHY does it change?",
        "description": "Physics-inspired analysis of energy, equilibrium, and flow.",
        "equations": {
            "Hamiltonian (Energy)": r"H = T + V = \frac{p^2}{2m} + V(q) \quad \text{(Total Energy)}",
            "Lagrangian (Motion)": r"L = T - V \quad \text{Action: } S = \int L \, dt",
            "Gibbs Free Energy": r"G = H - TS \quad \text{Spontaneous if } \Delta G < 0",
            "Angular Momentum": r"L = r \times p = I\omega",
            "Momentum Flux": r"\Pi_{ij} = \rho v_i v_j + p\delta_{ij} - \tau_{ij}",
            "Conservation": r"\frac{\partial \rho}{\partial t} + \nabla \cdot (\rho \mathbf{v}) = 0",
        },
    },
}


# =============================================================================
# INTERPRETATION TEMPLATES
# =============================================================================

def interpret_signal_typology(row: Dict[str, Any]) -> str:
    """Generate plain-language interpretation of signal typology."""
    parts = []

    # Classification
    signal_class = row.get("signal_class", "UNKNOWN")
    behavioral_type = row.get("behavioral_type", None)

    # Hurst/Memory interpretation
    hurst = row.get("hurst", None)
    if hurst is not None:
        if hurst > 0.65:
            parts.append(f"exhibits **persistent behavior** (H={hurst:.2f} > 0.5)")
        elif hurst < 0.35:
            parts.append(f"shows **anti-persistent behavior** (H={hurst:.2f} < 0.5)")
        else:
            parts.append(f"displays **random walk characteristics** (H={hurst:.2f} ‚âà 0.5)")

    # Persistence class
    persistence = row.get("persistence_class", None)
    if persistence:
        parts.append(f"persistence: **{persistence}**")

    # Periodicity interpretation
    is_periodic = row.get("is_periodic", False)
    if is_periodic:
        parts.append("contains **cyclical patterns**")
    else:
        parts.append("**non-periodic**")

    # Stationarity
    is_stationary = row.get("is_stationary", None)
    if is_stationary is True:
        parts.append("is **stationary** (stable statistics)")
    elif is_stationary is False:
        parts.append("is **non-stationary** (changing statistics)")

    # Volatility clustering
    has_vol_clustering = row.get("has_volatility_clustering", False)
    if has_vol_clustering:
        parts.append("has **volatility clustering** (variance changes over time)")

    # Chaos
    chaos_suspected = row.get("chaos_suspected", None)
    if chaos_suspected:
        parts.append("‚ö†Ô∏è **chaos suspected**")

    # Lyapunov
    lyapunov = row.get("lyapunov", None)
    if lyapunov is not None:
        if lyapunov > 0:
            parts.append(f"**chaotic** (Œª={lyapunov:.3f} > 0)")
        else:
            parts.append(f"**stable** (Œª={lyapunov:.3f} ‚â§ 0)")

    class_text = f"**{signal_class}**"
    if behavioral_type:
        class_text += f" ({behavioral_type})"

    return f"This signal is classified as {class_text}. It {', '.join(parts[:4])}."


def interpret_behavioral_geometry(row: Dict[str, Any]) -> str:
    """Generate plain-language interpretation of behavioral geometry (pairwise relationships)."""
    parts = []

    source = row.get("source", "?")
    target = row.get("target", "?")

    # Instant correlation
    instant_corr = row.get("instant_correlation", None)
    if instant_corr is not None:
        if abs(instant_corr) > 0.7:
            direction = "positively" if instant_corr > 0 else "negatively"
            parts.append(f"**{source}** and **{target}** are **strongly {direction} correlated** (œÅ={instant_corr:.3f})")
        elif abs(instant_corr) > 0.3:
            direction = "positive" if instant_corr > 0 else "negative"
            parts.append(f"**{source}** ‚Üí **{target}**: **moderate {direction} correlation** (œÅ={instant_corr:.3f})")
        else:
            parts.append(f"**{source}** and **{target}** are **weakly correlated** (œÅ={instant_corr:.3f})")

    # Optimal lag
    optimal_lag = row.get("optimal_lag", None)
    optimal_corr = row.get("optimal_correlation", None)
    if optimal_lag is not None and optimal_lag != 0:
        parts.append(f"Optimal lag: **{optimal_lag}** steps (œÅ={optimal_corr:.3f})")

    # Lead-lag direction
    lead_lag = row.get("lead_lag_direction", None)
    if lead_lag and lead_lag != "contemporaneous":
        parts.append(f"Relationship: **{lead_lag}**")

    # Coupling strength
    coupling = row.get("coupling_strength", None)
    if coupling is not None:
        if coupling > 0.5:
            parts.append(f"**Strong coupling** ({coupling:.3f})")
        elif coupling > 0.2:
            parts.append(f"Moderate coupling ({coupling:.3f})")

    # Mutual information
    mi = row.get("mutual_information", None)
    if mi is not None and mi > 0:
        parts.append(f"Mutual information: {mi:.3f} bits")

    return " | ".join(parts) if parts else "Pairwise relationship data available."


def interpret_dynamical_systems(row: Dict[str, Any]) -> str:
    """Generate plain-language interpretation of dynamical systems."""
    parts = []

    signal_id = row.get("signal_id", "Signal")

    # Regime information
    regime_id = row.get("regime_id", None)
    regime_mean = row.get("regime_mean", None)
    regime_std = row.get("regime_std", None)

    if regime_id is not None:
        parts.append(f"**{signal_id}** is in regime **{regime_id}**")
        if regime_mean is not None:
            parts.append(f"(Œº={regime_mean:.4f}, œÉ={regime_std:.4f})")

    # Stability state
    stability_state = row.get("stability_state", None)
    is_locally_stable = row.get("is_locally_stable", None)

    stability_map = {
        "stable": "‚úì **Locally stable** ‚Äî perturbations decay",
        "converging": "‚Üò **Converging** ‚Äî approaching equilibrium",
        "diverging_up": "‚Üó **Diverging upward** ‚Äî moving away from equilibrium",
        "diverging_down": "‚Üô **Diverging downward** ‚Äî moving away from equilibrium",
        "oscillating": "‚Üî **Oscillating** ‚Äî periodic fluctuations around equilibrium",
    }

    if stability_state:
        parts.append(stability_map.get(stability_state, f"State: **{stability_state}**"))

    if is_locally_stable is False:
        parts.append("‚ö†Ô∏è **Not locally stable**")

    # Phase velocity
    phase_velocity = row.get("phase_velocity", None)
    if phase_velocity is not None:
        if abs(phase_velocity) > 1:
            parts.append(f"**Fast dynamics** (v={phase_velocity:.3f})")
        elif abs(phase_velocity) < 0.1:
            parts.append(f"**Slow dynamics** (v={phase_velocity:.3f})")

    # Recurrence rate
    recurrence = row.get("recurrence_rate", None)
    if recurrence is not None:
        if recurrence > 100:
            parts.append(f"**High recurrence** ({recurrence:.1f}) ‚Äî deterministic/periodic")
        elif recurrence < 10:
            parts.append(f"**Low recurrence** ({recurrence:.1f}) ‚Äî chaotic/random")

    return " | ".join(parts) if parts else "Dynamical analysis available."


def interpret_causal_mechanics(row: Dict[str, Any]) -> str:
    """Generate plain-language interpretation of causal mechanics."""
    # Handle our SQL output format
    causal_role = row.get("causal_role", None)
    n_drives = row.get("n_drives", 0)
    n_driven_by = row.get("n_driven_by", 0)
    total_flow = row.get("total_causal_flow", 0)

    if causal_role:
        role_text = {
            "SOURCE": f"This signal is a **SOURCE** ‚Äî it drives {n_drives} other signal(s) but is not driven by any.",
            "SINK": f"This signal is a **SINK** ‚Äî it is driven by {n_driven_by} signal(s) but drives none.",
            "MEDIATOR": f"This signal is a **MEDIATOR** ‚Äî it both drives ({n_drives}) and is driven by ({n_driven_by}) other signals.",
            "ISOLATED": "This signal is **ISOLATED** ‚Äî no significant causal relationships detected.",
        }.get(causal_role, f"Causal role: **{causal_role}**")

        flow_text = f"Total causal flow: **{total_flow:.3f}**" if total_flow else ""

        drives = row.get("drives", "")
        driven_by = row.get("driven_by", "")

        relationships = []
        if drives:
            relationships.append(f"Drives: {drives}")
        if driven_by:
            relationships.append(f"Driven by: {driven_by}")

        rel_text = " | ".join(relationships) if relationships else ""

        return f"{role_text} {flow_text}\n\n{rel_text}".strip()

    # Fallback for different schema
    energy_class = row.get("energy_class", "UNKNOWN")
    equilibrium_class = row.get("equilibrium_class", "UNKNOWN")

    energy_text = {
        "conservative": "Energy is **conserved** ‚Äî a closed system with no external forcing.",
        "driven": "Energy is **increasing** ‚Äî external forces are injecting energy.",
        "dissipative": "Energy is **dissipating** ‚Äî the system is losing energy.",
        "fluctuating": "Energy **fluctuates irregularly** ‚Äî complex forcing dynamics.",
    }.get(energy_class.lower() if energy_class else "", f"Energy classification: **{energy_class}**.")

    equilibrium_text = {
        "approaching": "The system is **approaching equilibrium** spontaneously.",
        "at_equilibrium": "The system is **at equilibrium** ‚Äî a stable state.",
        "departing": "The system is **departing from equilibrium** ‚Äî investigate causes.",
        "forced": "The system is being **externally forced** ‚Äî non-spontaneous changes.",
    }.get(equilibrium_class.lower() if equilibrium_class else "", f"Equilibrium: **{equilibrium_class}**.")

    return f"{energy_text} {equilibrium_text}"


# =============================================================================
# DATA LOADING
# =============================================================================

@st.cache_data
def load_parquet(file) -> Optional[pl.DataFrame]:
    """Load a parquet file from upload."""
    try:
        return pl.read_parquet(file)
    except Exception as e:
        st.error(f"Failed to load file: {e}")
        return None


@st.cache_data
def load_parquet_from_path(path: str) -> Optional[pl.DataFrame]:
    """Load a parquet file from a file path."""
    try:
        return pl.read_parquet(path)
    except Exception as e:
        st.error(f"Failed to load {path}: {e}")
        return None


def get_unique_values(df: pl.DataFrame, column: str) -> List:
    """Get unique values from a column."""
    if column in df.columns:
        return sorted(df[column].unique().to_list())
    return []


def filter_data(df: pl.DataFrame, entity_id: str, timestamp: float) -> pl.DataFrame:
    """Filter dataframe by entity and timestamp."""
    filtered = df
    if entity_id and "entity_id" in df.columns:
        filtered = filtered.filter(pl.col("entity_id") == entity_id)
    if timestamp is not None and "timestamp" in df.columns:
        filtered = filtered.filter(pl.col("timestamp") == timestamp)
    return filtered


# =============================================================================
# CLAUDE INTEGRATION
# =============================================================================

SYSTEM_PROMPT = """You are an expert analyst helping users understand time series analysis results from the √òrthon framework.

√òrthon analyzes how relationships between system components evolve over time. The core insight is: "Systems lose coherence before they fail."

The framework has four layers:
1. **Signal Typology** (WHAT): Characterizes signals along 6 axes - memory, periodicity, volatility, discontinuity, impulsivity, complexity
2. **Behavioral Geometry** (HOW): Analyzes relationships between signals - correlation, clustering, network density
3. **Dynamical Systems** (WHEN/HOW): Tracks regime changes and stability over time
4. **Causal Mechanics** (WHY): Physics-inspired analysis of energy, equilibrium, and flow

Guidelines for your responses:
- Use domain-agnostic scientific language (works for turbines, chemistry, bearings, any system)
- Explain what the numbers mean in practical terms
- Highlight concerning patterns or anomalies
- Be concise but thorough
- Use analogies when helpful
- If you see signs of degradation or instability, say so clearly
- Avoid jargon unless you explain it"""


def get_data_context(dataframes: Dict[str, pl.DataFrame], entity_id: str, timestamp: float) -> str:
    """Build context string from current data state."""
    context_parts = []

    if entity_id:
        context_parts.append(f"Entity: {entity_id}")
    if timestamp is not None:
        context_parts.append(f"Time: t = {timestamp}")

    for layer_name, df in dataframes.items():
        if df is None:
            continue

        # Filter to current selection
        filtered = df
        if entity_id and "entity_id" in df.columns:
            filtered = filtered.filter(pl.col("entity_id") == entity_id)
        if timestamp is not None and "timestamp" in df.columns:
            filtered = filtered.filter(pl.col("timestamp") == timestamp)

        if len(filtered) == 0:
            # If no match with filters, show all data (limited)
            filtered = df.head(10)

        if len(filtered) == 0:
            continue

        # Get rows as dicts
        rows = filtered.to_dicts()[:5]  # Limit to 5 rows for context

        # Format layer data
        layer_info = f"\n**{layer_name.replace('_', ' ').title()}:**\n"
        for row in rows:
            row_info = []
            for key, value in row.items():
                if key in ['entity_id', 'timestamp']:
                    continue
                if isinstance(value, float):
                    row_info.append(f"{key}: {value:.4f}")
                else:
                    row_info.append(f"{key}: {value}")
            layer_info += "  - " + ", ".join(row_info[:6]) + "\n"

        context_parts.append(layer_info)

    return "\n".join(context_parts)


def ask_claude(question: str, data_context: str, api_key: str) -> str:
    """Send question to Claude with data context."""
    if not HAS_ANTHROPIC:
        return "Error: anthropic package not installed. Run `pip install anthropic`"

    try:
        client = anthropic.Anthropic(api_key=api_key)

        user_message = f"""Here is the current analysis data:

{data_context}

User question: {question}"""

        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1500,
            system=SYSTEM_PROMPT,
            messages=[{"role": "user", "content": user_message}]
        )

        return response.content[0].text

    except anthropic.AuthenticationError:
        return "Error: Invalid API key. Please check your Anthropic API key."
    except anthropic.RateLimitError:
        return "Error: Rate limit exceeded. Please wait a moment and try again."
    except Exception as e:
        return f"Error: {str(e)}"


# =============================================================================
# UI COMPONENTS
# =============================================================================

def render_equation_section(layer_key: str, expanded: bool = False):
    """Render the equations for a layer."""
    layer = EQUATIONS[layer_key]

    with st.expander(f"üìê Mathematical Foundations", expanded=expanded):
        st.markdown(f"*{layer['description']}*")

        cols = st.columns(2)
        for i, (name, eq) in enumerate(layer["equations"].items()):
            with cols[i % 2]:
                st.markdown(f"**{name}**")
                st.latex(eq)


def render_data_at_time(df: pl.DataFrame, layer_key: str, interpretation_fn):
    """Render data and interpretation for a specific time point."""
    if df is None or len(df) == 0:
        st.info("No data available for the selected filters.")
        return

    # Show metrics
    row = df.to_dicts()[0] if len(df) > 0 else {}

    # Display key metrics
    numeric_cols = [c for c in df.columns if df[c].dtype in [pl.Float64, pl.Float32, pl.Int64, pl.Int32]]

    if numeric_cols:
        cols = st.columns(min(4, len(numeric_cols)))
        for i, col in enumerate(numeric_cols[:8]):
            value = row.get(col, None)
            if value is not None and isinstance(value, (int, float)):
                with cols[i % 4]:
                    st.metric(
                        label=col.replace("_", " ").title(),
                        value=f"{value:.4f}" if isinstance(value, float) else value
                    )

    # Interpretation
    st.markdown("---")
    st.markdown("### üí° Interpretation")
    interpretation = interpretation_fn(row)
    st.markdown(f'<div class="interpretation">{interpretation}</div>', unsafe_allow_html=True)


def render_full_data(df: pl.DataFrame, layer_key: str):
    """Render full data table with optional filtering."""
    if df is None:
        return

    st.markdown("### üìä Full Dataset")
    st.dataframe(
        df.to_pandas(),
        use_container_width=True,
        height=300
    )

    # Summary statistics
    with st.expander("üìà Summary Statistics"):
        numeric_cols = [c for c in df.columns if df[c].dtype in [pl.Float64, pl.Float32, pl.Int64]]
        if numeric_cols:
            stats = df.select(numeric_cols).describe()
            st.dataframe(stats.to_pandas(), use_container_width=True)


# =============================================================================
# MAIN APP
# =============================================================================

def main():
    # Header
    st.markdown('<h1 class="main-header">‚óé √òrthon Explorer</h1>', unsafe_allow_html=True)
    st.markdown('<p class="tagline">geometry leads ‚Äî systems lose coherence before they fail</p>', unsafe_allow_html=True)

    # Sidebar: Data source selection
    st.sidebar.header("üìÅ Data Source")

    data_source = st.sidebar.radio(
        "Load data from:",
        ["Upload Files", "Output Directory"],
        index=1,
        help="Choose to upload parquet files or load from output/ directory"
    )

    dataframes = {}

    if data_source == "Upload Files":
        # File uploads
        uploaded_files = {}
        file_configs = [
            ("signal_typology", "Signal Typology", "Layer 1: WHAT is it?"),
            ("behavioral_geometry", "Behavioral Geometry", "Layer 2: HOW does it behave?"),
            ("dynamical_systems", "Dynamical Systems", "Layer 3: WHEN/HOW does it change?"),
            ("causal_mechanics", "Causal Mechanics", "Layer 4: WHY does it change?"),
            ("signal_class", "Signal Class", "Basic signal classification"),
        ]

        for key, label, help_text in file_configs:
            uploaded_files[key] = st.sidebar.file_uploader(
                f"{label}",
                type=["parquet"],
                key=f"upload_{key}",
                help=help_text
            )

        # Load dataframes
        for key, file in uploaded_files.items():
            if file is not None:
                dataframes[key] = load_parquet(file)

    else:
        # Load from output directory
        output_dir = Path(__file__).parent / "output"

        st.sidebar.markdown(f"**Path:** `{output_dir}`")

        file_configs = [
            ("signal_typology", "signal_typology.parquet"),
            ("behavioral_geometry", "behavioral_geometry.parquet"),
            ("dynamical_systems", "dynamical_systems.parquet"),
            ("causal_mechanics", "causal_mechanics.parquet"),
            ("signal_class", "signal_class.parquet"),
        ]

        for key, filename in file_configs:
            filepath = output_dir / filename
            if filepath.exists():
                dataframes[key] = load_parquet_from_path(str(filepath))
                st.sidebar.success(f"‚úì {filename}")
            else:
                st.sidebar.warning(f"‚úó {filename}")

    # Check if any data loaded
    if not any(df is not None for df in dataframes.values()):
        st.info("üëÜ Load parquet files to begin exploring your ORTHON analysis.")

        # Show example structure
        with st.expander("üìã Expected Files"):
            st.markdown("""
            The SQL engines produce these parquet files:

            - **signal_class.parquet** - Basic classification (analog/digital/periodic/event)
            - **signal_typology.parquet** - Full signal metadata and characteristics
            - **behavioral_geometry.parquet** - Geometric properties (curvature, torsion, fractal dimension)
            - **dynamical_systems.parquet** - Dynamics metrics (Lyapunov, entropy, stationarity)
            - **causal_mechanics.parquet** - Causal relationships (drives, driven_by, causal_role)

            Run the SQL engines first:
            ```bash
            cd orthon
            duckdb < sql/sql_engines/run_all.sql
            ```
            """)
        return

    # Sidebar: Filters
    st.sidebar.markdown("---")
    st.sidebar.header("üîç Filters")

    # Collect all unique signal_ids
    all_signals = set()

    for df in dataframes.values():
        if df is not None:
            if "signal_id" in df.columns:
                all_signals.update(df["signal_id"].unique().to_list())

    all_signals = sorted(list(all_signals))

    # Signal selector
    selected_signal = st.sidebar.selectbox(
        "Signal",
        options=["All"] + all_signals,
        index=0
    )
    if selected_signal == "All":
        selected_signal = None

    # Main content tabs
    tab_labels = ["üî¨ Analysis", "ü§ñ Ask Claude", "üìê Equations", "üìä Data Tables"]
    tabs = st.tabs(tab_labels)

    # TAB 1: Analysis
    with tabs[0]:
        st.markdown("## Analysis Overview")

        if selected_signal:
            st.info(f"üìç Showing analysis for signal: **{selected_signal}**")

        # Four columns for the four questions
        col1, col2 = st.columns(2)

        # WHAT - Signal Typology
        with col1:
            st.markdown('<div class="question-card what-card">', unsafe_allow_html=True)
            st.markdown("### üü¢ WHAT is it?")
            st.caption("Signal Typology ‚Äî Layer 1")

            if "signal_typology" in dataframes and dataframes["signal_typology"] is not None:
                df = dataframes["signal_typology"]
                if selected_signal and "signal_id" in df.columns:
                    df = df.filter(pl.col("signal_id") == selected_signal)

                if len(df) > 0:
                    render_data_at_time(df, "signal_typology", interpret_signal_typology)
                else:
                    st.warning("No signal typology data for selected filters.")
            elif "signal_class" in dataframes and dataframes["signal_class"] is not None:
                df = dataframes["signal_class"]
                if selected_signal and "signal_id" in df.columns:
                    df = df.filter(pl.col("signal_id") == selected_signal)

                if len(df) > 0:
                    render_data_at_time(df, "signal_class", interpret_signal_typology)
                else:
                    st.warning("No signal class data for selected filters.")
            else:
                st.info("Upload signal_typology.parquet to see WHAT analysis.")
            st.markdown('</div>', unsafe_allow_html=True)

        # HOW - Behavioral Geometry
        with col2:
            st.markdown('<div class="question-card how-card">', unsafe_allow_html=True)
            st.markdown("### üîµ HOW does it behave?")
            st.caption("Behavioral Geometry ‚Äî Layer 2")

            if "behavioral_geometry" in dataframes and dataframes["behavioral_geometry"] is not None:
                df = dataframes["behavioral_geometry"]
                if selected_signal and "signal_id" in df.columns:
                    df = df.filter(pl.col("signal_id") == selected_signal)

                if len(df) > 0:
                    render_data_at_time(df, "behavioral_geometry", interpret_behavioral_geometry)
                else:
                    st.warning("No geometry data for selected filters.")
            else:
                st.info("Upload behavioral_geometry.parquet to see HOW analysis.")
            st.markdown('</div>', unsafe_allow_html=True)

        col3, col4 = st.columns(2)

        # WHEN/HOW - Dynamical Systems
        with col3:
            st.markdown('<div class="question-card when-card">', unsafe_allow_html=True)
            st.markdown("### üü† WHEN/HOW does it change?")
            st.caption("Dynamical Systems ‚Äî Layer 3")

            if "dynamical_systems" in dataframes and dataframes["dynamical_systems"] is not None:
                df = dataframes["dynamical_systems"]
                if selected_signal and "signal_id" in df.columns:
                    df = df.filter(pl.col("signal_id") == selected_signal)

                if len(df) > 0:
                    render_data_at_time(df, "dynamical_systems", interpret_dynamical_systems)
                else:
                    st.warning("No dynamics data for selected filters.")
            else:
                st.info("Upload dynamical_systems.parquet to see WHEN/HOW analysis.")
            st.markdown('</div>', unsafe_allow_html=True)

        # WHY - Causal Mechanics
        with col4:
            st.markdown('<div class="question-card why-card">', unsafe_allow_html=True)
            st.markdown("### üü£ WHY does it change?")
            st.caption("Causal Mechanics ‚Äî Layer 4")

            if "causal_mechanics" in dataframes and dataframes["causal_mechanics"] is not None:
                df = dataframes["causal_mechanics"]
                if selected_signal and "signal_id" in df.columns:
                    df = df.filter(pl.col("signal_id") == selected_signal)

                if len(df) > 0:
                    render_data_at_time(df, "causal_mechanics", interpret_causal_mechanics)
                else:
                    st.warning("No mechanics data for selected filters.")
            else:
                st.info("Upload causal_mechanics.parquet to see WHY analysis.")
            st.markdown('</div>', unsafe_allow_html=True)

    # TAB 2: Ask Claude
    with tabs[1]:
        st.markdown("## ü§ñ Ask Claude About Your Data")
        st.markdown("*Get plain-language explanations of your analysis results.*")

        # API Key input
        api_key = st.text_input(
            "Anthropic API Key",
            type="password",
            help="Enter your Anthropic API key. Get one at console.anthropic.com",
            key="anthropic_api_key"
        )

        if not HAS_ANTHROPIC:
            st.warning("‚ö†Ô∏è The `anthropic` package is not installed. Run `pip install anthropic` to enable this feature.")

        # Build current data context
        data_context = get_data_context(dataframes, selected_signal, None)

        # Show current context
        with st.expander("üìã Current Data Context", expanded=False):
            st.markdown(data_context if data_context else "*No data loaded*")

        # Preset questions
        st.markdown("### Quick Questions")
        preset_cols = st.columns(2)

        preset_questions = [
            "What does this data tell me about system health?",
            "Are there any warning signs I should be concerned about?",
            "Explain the causal relationships in plain terms.",
            "What's causing the changes I'm seeing?",
            "How do the signals relate to each other?",
            "What should I monitor going forward?",
        ]

        selected_preset = None
        for i, q in enumerate(preset_questions):
            with preset_cols[i % 2]:
                if st.button(q, key=f"preset_{i}", use_container_width=True):
                    selected_preset = q

        # Custom question input
        st.markdown("### Or Ask Your Own Question")
        user_question = st.text_area(
            "Your question:",
            placeholder="e.g., Why is the correlation dropping? What does high volatility mean for my system?",
            height=100,
            key="user_question"
        )

        # Use preset if selected
        question_to_ask = selected_preset if selected_preset else user_question

        # Ask button
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            ask_button = st.button("üîç Ask Claude", type="primary", use_container_width=True)

        # Handle question
        if ask_button and question_to_ask:
            if not api_key:
                st.error("Please enter your Anthropic API key above.")
            elif not data_context or data_context.strip() == "":
                st.error("No data loaded. Please load parquet files first.")
            else:
                with st.spinner("Claude is analyzing your data..."):
                    response = ask_claude(question_to_ask, data_context, api_key)

                st.markdown("### Claude's Analysis")
                st.markdown(response)

                # Add to chat history
                if "chat_history" not in st.session_state:
                    st.session_state.chat_history = []
                st.session_state.chat_history.append({
                    "question": question_to_ask,
                    "answer": response,
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                })

        # Show chat history
        if "chat_history" in st.session_state and st.session_state.chat_history:
            st.markdown("---")
            st.markdown("### Previous Questions")
            for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):
                with st.expander(f"Q: {chat['question'][:50]}... ({chat['timestamp']})"):
                    st.markdown(f"**Question:** {chat['question']}")
                    st.markdown(f"**Answer:** {chat['answer']}")

    # TAB 3: Equations
    with tabs[2]:
        st.markdown("## Mathematical Foundations")
        st.markdown("*The equations underlying each analytical layer.*")

        for layer_key, layer_data in EQUATIONS.items():
            st.markdown(f"### {layer_data['title']}")
            st.markdown(f"*{layer_data['description']}*")

            cols = st.columns(2)
            for i, (name, eq) in enumerate(layer_data["equations"].items()):
                with cols[i % 2]:
                    st.markdown(f"**{name}**")
                    st.latex(eq)

            st.markdown("---")

    # TAB 4: Data Tables
    with tabs[3]:
        st.markdown("## Data Tables")

        for key, df in dataframes.items():
            if df is not None:
                with st.expander(f"üìÑ {key.replace('_', ' ').title()}", expanded=False):
                    # Apply filters
                    filtered = df
                    if selected_signal and "signal_id" in df.columns:
                        filtered = filtered.filter(pl.col("signal_id") == selected_signal)

                    st.dataframe(filtered.to_pandas(), use_container_width=True, height=300)

                    # Download button
                    csv = filtered.to_pandas().to_csv(index=False)
                    st.download_button(
                        label=f"üì• Download {key} CSV",
                        data=csv,
                        file_name=f"{key}_filtered.csv",
                        mime="text/csv"
                    )

    # Footer
    st.markdown("---")
    st.markdown(
        '<div class="footer">geometry leads ‚Äî √∏rthon | '
        'Systems lose coherence before they fail.</div>',
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
